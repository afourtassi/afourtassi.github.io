
---
---
References
==========

@article{fourtassiCDP,
	author = {Fourtassi, A.},
	title = {Understanding Children's Multimodal Conversational Development: Challenges and Opportunities},
    abstract = {Children’s ability to master skills for coordinated conversations is crucial for their healthy social and cognitive development. However, existing work has only partly addressed this phenomenon, and until recently, scientists have lacked the appropriate research tools to account for the entire complexity of this phenomenon. The main goal of this paper is to pinpoint the reasons that have made the study of conversation development a formidable challenge, drawing on insights from conversation analysis, pragmatics, psycholinguistics, and child development. In particular, our theories should account for (a) how children learn to coordinate across multiple levels (e.g., managing turn-taking, negotiating shared understanding, and engaging in coherent exchange with the interlocutor), (b) how they learn to use multimodal signaling in face-to-face interactions, and (c) how they adapt to the communicative conventions of their linguistic community while using their skills flexibly across various conversational contexts. I outline one promising research approach that has the potential to better handle this elusive phenomenon; an approach that capitalizes on new technological opportunities in remote data collection methods and high-scalability Machine Learning tools to help provide a quantitative understanding of how children grow to become competent communicators.},
	year = {under review},
    link ={https://psyarxiv.com/4f3ny}
    }

@article{MazzoconiLaugh,
	author = {Mazzoconi, C. and O'Brien, B. and El Haddad, K. and Bodur, K. and Fourtassi, A},
	title = {Differences between Mimicking and Non-Mimicking laughter in Child-Caregiver Conversation: A Distributional and Acoustic Analysis},
    abstract = {Despite general agreement that laughter is crucial in social interactions and cognitive development, there is surprisingly little work looking at its use through childhood. Here we investigate laughter in middle childhood, using a corpus of online calls between child and parent and between the (same parent) and another adult. We focus on laughter mimicry, i.e., laughter shortly following laughter from the partner, and we compare mimicking and non-mimicking laughter in terms of distribution and acoustic properties using spectrotemporal modulation measures. Our results show, despite similar frequencies in laughter production, different laughter mimicry patterns between Parent-Child and Parent-Adult interactions. Overall, in comparison with previous work in infants and toddlers, our results show laughter mimicry is more balanced between parents and school-age children. At the acoustic level, we observe differences between mimicking and non-mimicking laughter in children, but not in adults. Moreover, we observe significant differences in laughter acoustics in parents depending on whether they interact with children or adults, which highlights a strong interlocutor effect on laughter mimicry.},
	year = {under review}
    }
    
@article{NikolausCogSci2023,
	author = {Nikolaus, M. and Prévot, L. and Fourtassi, A. },
	title = {Communicative Feedback Signals in Response to Children’s Grammatical Errors},
    abstract = {Children learning their mother tongue engage in interactive communication starting from the early stages of their development. In a large-scale study of transcribed child-caregiver conversations, we investigated the role of Communicative Feedback in response to children's grammatical errors. We found evidence for both positive and negative feedback signals that are useful for learning the grammar of one's native language: Caregivers are more likely to provide acknowledgments if an utterance is grammatical, and they are more likely to ask for clarification if an utterance is ungrammatical. Further, we investigate how children react in response to negative communicative feedback signals and find evidence that grammaticality is improved in direct follow-ups to negative feedback signals. This study provides the largest and most comprehensive evidence supporting the presence and effectiveness of communicative feedback signals in grammar learning, broadening the literature on communicative feedback in language acquisition more generally.},
	year = {under review}
    }
    
@article{CabidduCogSci,
	author = {Cabiddu, F. and Nikolaus, M. and Fourtassi, A.},
	title = {Modeling Children's Word Sense Disambiguation with Large Language Models: Insights and Challenges},
    abstract = {Understanding how children process ambiguous words is a challenge because sense disambiguation depends on sentence context bottom-up and top-down aspects. Here, we seek insight into this phenomenon by investigating how such a competence might arise in large distributional learners (Transformers) that purport to acquire sense representations from language input in a largely unsupervised fashion. We investigated how sense disambiguation might be achieved using model representations derived from naturalistic child-directed speech. We tested a large pool of Transformer models, varying in their pretraining input size/nature as well as the size of their parameter space. Tested across three behavioral experiments from the developmental literature, we found that these models capture some essential properties of child sense disambiguation, although most still struggle in the more challenging tasks with contrastive cues. We discuss implications for both theories of word learning and for using Transformers to capture child language processing.},
	year = {under review}
    }
    
@article{AgrawalCogSci,
	author = {Agrawal, A. and Liu, J. and Bodur, K. and Favre, B. and Fourtassi, A.},
	title = {Development of Multimodal Turn Coordination in Conversations: Evidence for Adult-like behavior in Middle Childhood},
    abstract = {The question of how children develop multimodal coordination skills to engage in meaningful face-to-face conversations is crucial for our broader understanding of children's healthy socio-cognitive development. Here we focus on investigating the ability of school-age children to coordinate turns with their interlocutors, especially regarding when to take the floor (i.e., the main channel of the conversation) and when to provide attentive listening signals via the back channel.  Using data of child-caregiver naturalistic conversations and data-driven research tools, we found that children aged 6 to 12 years old already show adult-like behavior both in terms of reacting to the relevant channel-specific cues and in terms of providing reliable, multimodal inviting cues to help their interlocutor select the most appropriate channel of the conversation.},
	year = {under review}
    }
    
    
@article{bodurjournal,
	author = {Bodur, K. and Nikolaus, M. and Prévot, L.  and Fourtassi, A.},
	title = {Using video calls to study children’s conversational development: The case of backchannel signaling},
    abstract = {Understanding how children’s conversational skills develop is crucial for understanding their social, cognitive, and linguistic development, with important applications in health and education. To develop theories based on quantitative studies of conversational development, we need (i) data recorded in naturalistic contexts (e.g. child-caregiver dyads talking in their daily environment) where children are more likely to show much of their conversational competencies, as opposed to controlled laboratory contexts which typically involve talking to a stranger (e.g., the experimenter); (ii) data that allows for clear access to children’s multimodal behavior in face-to-face conversations; and (iii) data whose acquisition method is cost-effective with the potential of being deployed at a large scale to capture individual and cultural variability. The current work is a first step to achieve this goal. We built a corpus made of video chats involving children in middle childhood (6-12 years old) and their caregivers using a weakly structured word-guessing game to prompt spontaneous conversation. The manual annotations of these recordings have shown the similarity of the frequency distribution of multimodal communicative signals from both children and caregivers. As a case study, we capitalize on this rich behavioral data to study how both verbal and non-verbal cues contribute to the development of conversational coordination. In particular, we looked at how children learn to engage in coordinated conversations not only as speakers but also as listeners by analyzing children’s use of backchannel signaling (e.g., verbal 'mh' or head nods) during these conversations. Contrary to results from previous in-lab studies, our use of both more natural/spontaneous conversational settings and more adequate controls allowed us to reveal that school-age children are strikingly close to adult-level mastery in many measures of backchanneling. Our work demonstrates the usefulness of recent technology in video calling for acquiring quality data that can be used for research on children’s conversational development in the wild.},
	year = {2023}, 
    volume = {5},
    journal={Frontiers in Computer Science},
    repo = {https://github.com/afourtassi/ChiCo-Annotation},
    link = {https://www.frontiersin.org/articles/10.3389/fcomp.2023.1088752/full?utm_source=F-NTF&utm_medium=EMLX&utm_campaign=PRD_FEOPS_20170000_ARTICLE}
    }
    

@article{wilsonJournal,
	author = {Wilson, K. and Frank, M. C. and Fourtassi, A},
	title = {Conceptual Hierarchy in Child-Directed Speech: Implicit Cues are More Reliable},
    link = {https://psyarxiv.com/tx47e},
    abstract = {In order for children to understand and reason about the world in an adult-like fashion, they need to learn that conceptual categories are organized in a hierarchical fashion (e.g., a dog is also an animal). The caregiver’s linguistic input can play an important role in this learning, and previous studies have documented several cues in parental talk that can help children learn the conceptual hierarchy. However, these previous studies used different datasets and methods which made difficult the systematic comparison of these cues and the study of their relative contribution. Here, we use a large-scale corpus of child-directed speech and a classification-based evaluation method which allowed us to investigate, within the same framework, various cues that vary radically in terms of how explicit the information they offer is. We found the most explicit cues to be too sparse or too noisy to support robust learning. In contrast, the implicit cues offered, overall, a reliable source of information. Our work confirms the utility of caregiver talk for conveying conceptual information. It provides a stepping stone towards a cognitive model that would use this information in a principled way, leading to testable predictions about children’s conceptual development.},
	year = {2023},
    journal={Journal of Cognition & Development},
    repo = {https://github.com/afourtassi/ChiCo-Annotation}
    }
    
    

@article{nikolaus2023theory,
	author = {Nikolaus, M. and Fourtassi, A.},
	title = {Communicative Feedback in Language Acquisition},
	link = {https://psyarxiv.com/k63uv/},
    abstract = {Children start to communicate and use language in social interactions from a very young age. This allows them to experiment with their developing linguistic knowledge and receive valuable feedback from their -- often more knowledgeable -- interlocutors. While research in language acquisition has focused a great deal on children's ability to learn from the linguistic input or social cues, very little work has investigated the nature and role of communicative feedback, a process that results from children and caregivers trying to coordinate mutual understanding. In this work, we draw on insights from theories of communicative coordination to formalize a mechanism for language acquisition: We argue that children can improve their linguistic knowledge in conversation by leveraging explicit or implicit signals of communication success or failure. This new formalization provides a common framework for several lines of research in child development that have been pursued separately. Further, it points towards several gaps in the literature that, we believe, should be addressed in future research in order to achieve a more complete understanding of language acquisition within and through social interaction.},
	year = {2023},
    volume = {69},
    journal={New Ideas in Psychology}
    }
    
    
    
@inproceedings{kubra2022cogsci,
	author = {Bodur, K. and Nikolaus, M. and Prevot, L. and Fourtassi, A.},
	title = {Backchannel Behavior in Child-Caregiver Video Calls},
    link = {https://psyarxiv.com/cvnqm},
    abstract = {An important step in children's socio-cognitive development is learning how to engage in coordinated conversations. This requires not only becoming competent speakers but also active listeners. This paper studies children's use of backchannel signaling (e.g., "yeah!" or a head nod) when in the listener's role during conversations with their caregivers via Zoom. While previous work had found backchannel to be still immature in middle childhood, our use of both more natural/spontaneous conversational settings and more adequate controls allowed us to reveal that school-age children are strikingly close to adult-level mastery in many measures of backchanneling. The broader impact of this paper is to highlight the crucial role of social context in evaluating children's conversational abilities.},
	year = {2022},
    link = {https://psyarxiv.com/cvnqm},
    repo = {https://github.com/cocodev-team/video-calls-project},
    booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society}
    }
    
@article{chiara2022,
	author = {Chiara Mazzocconi and Jonathan Ginzburg},
	title = {A Longitudinal Characterization of Typical Laughter Development in Mother–Child Interaction from 12 to 36 Months: Formal Features and Reciprocal Responsiveness},
    abstract = {Laughter is a valuable means for communicating and engaging in interaction since the earliest months of life. Nevertheless, there is a dearth of work on how its use develops in early interactions—given its putative reflexive nature, it has often been disregarded from studies on pre-linguistic vocalizations. We provide a longitudinal characterization of laughter use analyzing interactions of 4 babies with their mothers at five time-points (12, 18, 24, 30, and 36 months). We show how child laughter is very distinct from mothers’ (and adults’ generally), in terms of frequency, duration, level of arousal displayed, overlap with speech, and responsiveness to others’ laughter. Notably, contrary to what might be expected, we observed that children laugh significantly less than their mothers, especially at the first time-points analyzed. We indeed observe an increasing developmental trajectory in the production of laughter overall and in the contingent multimodal response to mothers’ laughter, showing the child’s increasing attunement to the social environment, interest in others’ appraisals and mental states, and awareness of its communicative value. We also show how mothers’ contingent responses to child laughter change over time, going from high-frequency mimicry, to a lower rate of diversified multimodal responses, in line with the child’s neuro-psychological development. Our data support a dynamic view of dialogue where interactants influence each other bidirectionally and emphasizes the crucial communicative value of laughter. When language is not fully developed, laughter might be an early means, in its already fully available expressiveness, to hold the conversational turn and enable meaningful vocal contribution in interaction at the same level of the interlocutor. Our study aims to provide a benchmark for typical laughter development, since we believe it can be an early means, along with other commonly analyzed behaviors (e.g., smiling, gazing, pointing, etc.), to gain insight into early child neuro-psychological development.},
	year = {2022},
    volume={46},
    link = {https://link.springer.com/article/10.1007/s10919-022-00403-8},
    repo = {https://osf.io/48fmd/?view_only=a3bcf69ab71f43fdac820b1e46c6e5de},
    journal={Journal of Nonverbal Behavior}
    }
    
    
    
@inproceedings{nikolaus2022cogsci,
	author = {Nikolaus, Mitja and Prevot, Laurent and Fourtassi, Abdellah},
	title = {Communicative Feedback as a Mechanism Supporting the Production of Intelligible Speech in Early Childhood},
    abstract = {Children start to communicate and use language in social interactions from very early stages in development. This allows them to experiment with their current linguistic knowledge and receive valuable feedback from their interlocutors. We conducted a large-scale corpus study to examine the quality of positive and negative Communicative Feedback signals that caregivers provide in terms of responsiveness and clarification requests. We found evidence for the effect of such feedback in supporting children’s production of intelligible speech. The broad impact of this paper is to highlight how general social feedback mechanisms that govern human communication can also support child language acquisition.},
	year = {2022},
    link = {https://psyarxiv.com/sg5mv},
    repo = {https://github.com/mitjanikolaus/childes-communicative-feedback},
    booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society}

    }
    
@inproceedings{nikolaus2022emnlp,
	author = {Nikolaus, M. and Salin, E. and Ayache, S. and Fourtassi, A. and Favre, B.},
	title = {Do Vision-and-Language Transformers Learn Predicate-Noun Dependencies?},
    abstract = {Recent advances in vision-and-language modeling have seen the development of Transformer architectures that achieve remarkable performance on multimodal reasoning tasks. Yet, the exact capabilities of these black-box models are still poorly understood. While much of previous work has focused on studying their ability to learn meaning at the wordlevel, their ability to track syntactic dependencies between words has received less attention. We take a first step in closing this gap by creating a new multimodal task targeted at evaluating understanding of predicate-noun dependencies in a controlled setup. We evaluate a range of state-of-the-art models and find that their performance on the task varies considerably, with some models performing relatively well and others at chance level. In an effort to explain this variability, our analyses indicate that the quality (and not only sheer quantity) of pretraining data is essential. Additionally, the best performing models leverage finegrained multimodal pretraining objectives in addition to the standard image-text matching objectives. This study highlights that targeted and controlled evaluations are a crucial step for a precise and rigorous test of the multimodal knowledge of vision-and-language models.},
	year = {2022},
    link = {https://arxiv.org/pdf/2210.12079.pdf},
    repo = {https://github.com/cocodev-team/multimodal-Transformer-noun-dependencies},
    booktitle={Proceedings of The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)}
    }
    
@inproceedings{Misiek2022align,
	author = {Misiek, T. and Fourtassi, A.},
	title = {Caregivers Exaggerate Their Lexical Alignment to Young Children Across Several Cultures},
    abstract = {As soon as they start producing their first words, children engage in dialogues with people around them. Recent work has suggested that caregivers facilitate this early linguistic communication via frequently re-using and building on children's own words. This tendency decreases over development as children become more competent speakers. While this pattern has been observed with data of English-learning children, the question remains as to whether this early child-caregiver dynamics is universal vs. culture-specific. We address this question using large-scale data in six languages belonging to both Eastern and Western cultures. We found that the finding generalizes well cross-linguistically, suggesting that caregivers' early "exaggerating" of lexical alignment is likely a scaffolding strategy used across cultures to facilitate children's early linguistic communication and learning.},
	year = {2022},
    link = {https://psyarxiv.com/smu9e},
    repo = {https://github.com/thomasMisiek/children-linguistic-alignment},
    booktitle={Proceedings of the Workshop on the Semantics and Pragmatics of Dialogue (SemDial)}
    }
    
@inproceedings{Hallart2022,
	author = {Hallart, C. and Peirolo, M. and Xu, Z. and Fourtassi, A.},
	title = {Contingency in Child-Caregiver Naturalistic Conversation: Evidence for Mutual Influence},
    abstract = {To be able to hold conversations with people around them, children need to learn contingency, i.e., the ability to contribute to a dialog with relevant utterances. We study this skill in the context of child-caregiver naturalistic interactions, using question-initiated sequences as units of analysis. While much of previous work has focused on the caregiver or on the child, here we study contingency in the dyad as a whole, allowing for a deeper understanding of how interlocutors influence each other.},
	year = {2022},
    link = {https://psyarxiv.com/cev8k},
    booktitle={Proceedings of the Workshop on the Semantics and Pragmatics of Dialogue (SemDial)}
    }
    
@inproceedings{Liu2022,
	author = {Liu, J. and Nikolaus, M. and  Bodur, K. and Fourtassi, A.},
	title = {Predicting Backchannel Signaling in Child-Caregiver Multimodal Conversations},
    abstract = {Conversation requires cooperative social interaction between interlocutors. In particular, active listening through backchannel signaling (hereafter BC) i.e., showing attention through verbal (short responses like ``Yeah'') and non-verbal behaviors (e.g. smiling or nodding) is crucial to managing the flow of a conversation and it requires sophisticated coordination skills. How does BC develop in childhood? Previous studies were either conducted in highly controlled experimental settings or relied on qualitative corpus analysis, which does not allow for a proper understanding of children's BC development, especially in terms of its collaborative/coordinated use. This paper aims at filling this gap using a machine learning model that learns to predict children's BC production based on the interlocutor's inviting cues in child-caregiver naturalistic conversations. By comparing BC predictability across children and adults, we found that, contrary to what has been suggested in previous in-lab studies, children between the ages of 6 and 12 can actually produce and respond to backchannel inviting cues as consistently as adults do, suggesting an adult-like form of coordination.},
	year = {2022},
    link = {https://psyarxiv.com/pgvy2},
    repo = {https://github.com/Jing-L97/BC-Prediction},
    booktitle={Proceedings of the International Conference on Multimodal Interaction (ICMI'22 Companion)}
    }
    
@article{nikolaus2022peppa,
	author = {Nikolaus, Mitja and Alishahi, Afra and Chrupa{\l}a, Grzegorz},
	title = {Learning English with Peppa Pig},
    link = {https://arxiv.org/pdf/2202.12917.pdf},
    abstract = {Attempts to computationally simulate the acquisition of spoken language via grounding in perception have a long tradition but have gained momentum in the past few years. Current neural approaches exploit associations between the spoken and visual modality and learn to represent speech and visual data in a joint vector space. A major unresolved issue from the point of ecological validity is the training data, typically consisting of images or videos paired with spoken descriptions of what is depicted. Such a setup guarantees an unrealistically strong correlation between speech and the visual world. In the real world the coupling between the linguistic and the visual is loose, and often contains confounds in the form of correlations with non-semantic aspects of the speech signal. The current study is a first step towards simulating a naturalistic grounding scenario by using a dataset based on the children's cartoon Peppa Pig. We train a simple bi-modal architecture on the portion of the data consisting of naturalistic dialog between characters, and evaluate on segments containing descriptive narrations. Despite the weak and confounded signal in this training data our model succeeds at learning aspects of the visual semantics of spoken language.},
	year = {2022},
    repo = {https://github.com/mitjanikolaus/peppa},
    journal={Transactions of the Association for Computational Linguistics}
    }
    
    
    
@article{nikolaus2022acts,
	author = {Nikolaus, Mitja and Maes, Eliot and Auguste, Jeremy and Prevot, Laurent and Fourtassi, Abdellah},
	title = {Large-scale study of speech acts' development in early childhood},
	link = {https://psyarxiv.com/xs8k6/},
    abstract = {Studies of children's language use in the wild (e.g., in the context of child-caregiver social interaction) have been slowed by the time- and resource- consuming task of hand annotating utterances for communicative intents/speech acts. Existing studies have typically focused on investigating rather small samples of children, raising the question of how their findings generalize both to larger and more representative populations and to a richer set of interaction contexts. Here we propose a simple automatic model for speech act labeling in early childhood based on the INCA-A coding scheme (Ninio, Snow, Pan, & Rollins, 1994). After validating the model against ground truth labels, we automatically annotated the entire English-language data from the CHILDES corpus. The major theoretical result was that earlier findings generalize quite well at a large scale. Further, we introduced two complementary measures for the age of acquisition of speech acts which allows us to rank different speech acts according to their order of emergence in production and comprehension.Our model will be shared with the community so that researchers can use it with their data to investigate various question related to language use both in typical and atypical populations of children.},
    repo = {https://github.com/mitjanikolaus/childes-speech-acts},
    journal={Language Development Research},
    volume = {2},
    number = {1},
	year = {2022}
    }
    
    
@article{jiang2022,
	author = {Jiang, Hang and Frank, Michael C and Kulkarni, Vivek and Fourtassi, Abdellah},
	title = {Exploring patterns of stability and change in caregivers' word usage across early childhood},
	link = {https://psyarxiv.com/fym86},
    abstract = {The linguistic input children receive across early childhood plays a crucial role in shaping their knowledge about the world. To study this input, researchers have begun applying distributional semantic models to large corpora of child-directed speech, extracting various patterns of word use/co-occurrence. Previous work using these models has not measured how these patterns may change throughout development, however. In this work, we leverage NLP methods that were originally developed to study historical language change to compare caregivers' use of words when talking to younger vs. older children. Some words' usage changed more than others'; this variability could be predicted based on the word's properties at both the individual and category level. These findings suggest that caregivers' changing patterns of word use may play a role in scaffolding children's acquisition of conceptual structure in early development.},
    repo = {https://github.com/afourtassi/change},
	year = {2022},
    voluùe = {46},
    number = {7},
    journal={Cognitive Science}
    }
    


@article{dautriche2021subkective,
title = {Subjective confidence influences word learning in a cross-situational statistical learning task},
journal = {Journal of Memory and Language},
volume = {121},
year = {2021},
author = {Isabelle Dautriche and Hugh Rabagliati and Kenny Smith},
keywords = {Word learning, Cross-situational learning, Confidence, Metacognition},
abstract = {Learning is often accompanied by a subjective sense of confidence in one’s knowledge, a feeling of knowing what you know and how well you know it. Subjective confidence has been shown to guide learning in other domains, but has received little attention so far in the word learning literature. Across three word learning experiments, we investigated whether and how a sense of confidence in having acquired a word meaning influences the word learning process itself. First, we show evidence for a confirmation bias during word learning in a cross-situational statistical learning task: Learners who are highly confident they know the meaning of a word are more likely to persist in their belief than learners who are not, even after observing objective evidence disconfirming their belief. Second, we show that subjective confidence in a word meaning modulates inferential processes based on that word, affecting learning over the whole lexicon: Learners who hold high confidence in a word meaning are more likely to use that word to make mutual exclusivity inferences about the meaning of other words. We conclude that confidence influences word learning by modulating both information selection processes and inferential processes and discuss the implications of these results for word learning models.},
link = {https://psyarxiv.com/84bqu},
repo = {https://osf.io/upndk/}
}




@inproceedings{nikolaus2021production,
	author = {Nikolaus, M. and Fourtassi, A.},
    title = {Modeling the Interaction Between Perception-Based and Production-Based Learning in Children's Early Acquisition of Semantic Knowledge},
    booktitle={Proceedings of the Conference on Computational Natural Language Learning (CoNLL)},
	abstract = {Children learn the meaning of words and sentences in their native language at an impressive speed and from  highly ambiguous input. To account for this learning, previous computational modeling has focused mainly on the study of perception-based mechanisms like cross-situational learning. However, children do not learn only by exposure to the input. As soon as they start to talk, they practice their knowledge in social interactions and they receive feedback from their caregivers. In this work, we propose a model integrating both perception- and production-based learning using artificial neural networks which we train on a large corpus of crowd-sourced images with corresponding descriptions. We found that production-based learning improves performance above and beyond perception-based learning across a wide range of semantic tasks including both word- and sentence-level semantics. In addition, we documented a synergy between these two mechanisms, where their alternation allows the model to converge on more balanced semantic knowledge. The broader impact of this work is to highlight the importance of modeling language learning in the context of social interactions where children are not only understood as passively absorbing the input, but also as actively participating in the construction of their linguistic knowledge.},
	year = {2021},
    link = {https://psyarxiv.com/at47v},
    repo = {https://github.com/mitjanikolaus/perception-and-production-based-learning}
    }
    
    
@article{franccois2021signatures,
  title={Signatures of brain plasticity supporting language recovery after perinatal arterial ischemic stroke},
  author={François, Clément and Garcia-Alix, Alfredo and Bosch, Laura and Rodriguez-Fornells, Antoni},
  journal={Brain and Language},
  volume={212},
  abstract = {Brain imaging methods such as functional Magnetic Resonance Imaging (fMRI) and Diffusion Tensor Imaging (DTI) have already been used to decipher the functional and structural brain changes occurring during normal language development. However, little is known about the differentiation of the language network after an early lesion. While in adults, stroke over the left hemisphere generally induces post-stroke aphasia, it is not always the case when a stroke occurs in the perinatal period, thus revealing a remarkable plastic power of the language network during early development. In particular, the role of perilesional tissues, as opposed to undamaged brain areas in the functional recovery of language functions after an early insult, remains unclear. In this review article, we provide an overview of the extant literature using functional and structural neuroimaging data revealing the signatures of brain plasticity underlying near-normal language development},
  link = {https://www.sciencedirect.com/science/article/pii/S0093934X20301395},
  year = {2021}
}


@article{schatz2021Do,
    author = {Feldman, Naomi H. and Goldwater, Sharon and Dupoux, Emmanuel and Schatz, Thomas},
    title = "{Do Infants Really Learn Phonetic Categories?}",
    journal = {Open Mind},
    pages = {1-19},
    year = {2021},
    abstract = {Early changes in infants’ ability to perceive native and nonnative speech sound contrasts are typically attributed to their developing knowledge of phonetic categories. We critically examine this hypothesis and argue that there is little direct evidence of category knowledge in infancy. We then propose an alternative account in which infants’ perception changes because they are learning a perceptual space that is appropriate to represent speech, without yet carving up that space into phonetic categories. If correct, this new account has substantial implications for understanding early language development.},
    link = {https://direct.mit.edu/opmi/article-pdf/doi/10.1162/opmi\_a\_00046/1966581/opmi\_a\_00046.pdf},
}


@inproceedings{fourtassi2020word,
  title={Word Co-occurrence in Child-Directed Speech Predicts Children’s Free Word Associations},
  author={Fourtassi, Abdellah},
  booktitle={Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics},
  pages={49--53},
  year={2020},
  link ={https://psyarxiv.com/7jrhu},
  abstract = {The free association task has been very influential both in cognitive science and in computational linguistics. However, little research has been done to study how free associations develop in childhood. The current work focuses on the developmental hypothesis according to which free word associations emerge by mirroring the co-occurrence distribution of children's linguistic environment. I trained a distributional semantic model on a large corpus of child language and I tested if it could predict children's responses. The results largely supported the hypothesis: Co-occurrence-based similarity was a strong predictor of children's associative behavior even controlling for other possible predictors such as phonological similarity, word frequency, and word length. I discuss the findings in the light of theories of conceptual development.}
}

@inproceedings{misiek2020development,
  title={Development of Multi-level Linguistic Alignment in Child-Adult Conversations},
  author={Misiek, Thomas and Favre, Benoit and Fourtassi, Abdellah},
  booktitle={Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics},
  pages={54--58},
  year={2020},
  link = {https://psyarxiv.com/5drp9/},
  repo = {https://github.com/thomasMisiek/children-linguistic-alignment},
  abstract = {Interactive alignment is a major mechanism of linguistic coordination. Here we study the way this mechanism emerges in development across the lexical, syntactic, and conceptual levels. We leverage NLP tools to analyze a large-scale corpus of child-adult conversations between 2 and 5 years old. We found that, across development, children align consistently to adults above chance and that adults align consistently more to children than vice versa (even controlling for language production abilities). Besides these consistencies, we found a diversity of developmental trajectories across linguistic levels. These corpus-based findings provide strong support for an early onset of multi-level linguistic alignment in children and invite new experimental work.}
}

@inproceedings{bodur2021,
  title={ChiCo: A Multimodal Corpus for the Study of Child Conversation},
  author={Bodur, K. and Nikolaus, M. and Kassim, F. and Prévot, L. and Fourtassi, A.},
  year={2021},
  booktitle = {Proceedings of the International Conference on Multimodal Interaction (ICMI'21 Companion)},
  pages = {158–163},
  abstract = {The study of how children develop their conversational skills is an important scientific frontier at the crossroad of social, cognitive, and linguistic development with important applications in health, education, and child-oriented AI. While recent advances in machine learning techniques allow us to develop formal theories of conversational development in real-life contexts, progress has been slowed down by the lack of corpora that both approximate naturalistic interaction and provide clear access to children's non-verbal behavior in face-to-face conversations. This work is an effort to fill this gap. We introduce ChiCo (for Child Conversation), a corpus we built using an online video chat system. Using a weakly structured task (a word-guessing game), we recorded 20 conversations involving either children in middle childhood (i.e., 6 to 12 years old) interacting with their caregivers (condition of interest) or the same caregivers interacting with other adults (a control condition), resulting in 40 individual recordings. Our annotation of these videos has shown that the frequency of children's use of gaze, gesture and facial expressions mirrors that of adults. Future modeling research can capitalize on this rich behavioral data to study how both verbal and non-verbal cues contribute to the development of conversational coordination.},
  repo= {https://osf.io/5ngwc/},
  link= {https://psyarxiv.com/uzfes}
  }
  
@inproceedings{nikolaus2021evaluating,
  title={Evaluating the Acquisition of Semantic Knowledge from Cross-situational Learning in Artificial Neural Networks},
  author={Nikolaus, Mitja and Fourtassi, Abdellah},
  booktitle={Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics},
  pages={200--210},
  year={2021},
  repo = {https://github.com/mitjanikolaus/cross-situational-learning-abstract-scenes},
  link = {https://psyarxiv.com/mbesf},
  abstract = {When learning their native language, children acquire the meanings of words and sentences from highly ambiguous input without much explicit supervision. One possible learning mechanism is cross-situational learning, which has been successfully tested in laboratory experiments with children. Here we use Artificial Neural Networks to test if this mechanism scales up to more natural language and visual scenes using a large dataset of crowd-sourced images with corresponding descriptions. We evaluate learning using a series of tasks inspired by methods commonly used in laboratory studies of language acquisition. We show that the model acquires rich semantic knowledge both at the word- and sentence-level, mirroring the patterns and trajectory of learning in early childhood. Our work highlights the usefulness of low-level co-occurrence statistics across modalities in facilitating the early acquisition of higher-level semantic knowledge.}
}

@inproceedings{nikolaus2021large,
  title={Large-scale study of speech acts' development using automatic labelling},
  author={Nikolaus, Mitja and Maes, Juliette and Auguste, Jeremy and Prevot, Laurent and Fourtassi, Abdellah},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  year={2021},
  repo = {https://github.com/mitjanikolaus/childes-speech-acts},
  link = {https://psyarxiv.com/j4smd/},
  abstract = {Studies of children's language use in the wild (e.g., in the context of child-caregiver social interaction) have been slowed by the time- and resource- consuming task of hand annotating utterances for communicative intents/speech acts. Existing studies have typically focused on investigating rather small samples of children, raising the question of how their findings generalize both to larger and more representative populations and to a richer set of interaction contexts. Here we propose a simple automatic model for speech act labeling in early childhood based on the INCA-A coding scheme (Ninio et al., 1994). After validating the model against ground truth labels, we automatically annotated the entire English-language data from the CHILDES corpus. The major theoretical result was that earlier findings generalize quite well at a large scale. Our model will be shared with the community so that researchers can use it with their data to investigate various questions related to language use development.}
}

@inproceedings{nikolaus2021modeling,
  title={Modeling speech act development in early childhood: the role of frequency and linguistic cues},
  author={Nikolaus, Mitja and Maes, Juliette and Fourtassi, Abdellah},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society.},
  year={2021},
  repo = {https://github.com/mitjanikolaus/childes-speech-acts},
  link = {https://psyarxiv.com/cgs5n},
  abstract = {A crucial step in children’s language development is the mastery of how to use language in context. This involves the ability to recognize and use major categories of speech acts (e.g., learning that a “question” is different from a “request”). The current work provides a quantitative account of speech acts’ emergence in the wild. Using a longitudinal corpus of child-caregiver conversations annotated for speech acts (Snow et al., 1996), we introduced two complementary measures of learning based on both children’s production and comprehension. We also tested two predictors of learning based on the input frequency and the speech acts’ quality of linguistic cues. We found that children’s developmental trajectory differed largely between production and comprehension. In addition, development in both of these dimensions was not explained with the same predictors (e.g., frequency in the child-directed speech was predictive of production, but not of comprehension). The broader impact of this work is to provide a computational framework for the study of communicative development where both measures and predictors of children’s pragmatic development can be tested and compared.}
}



}

@article {Schatze2021early,
	author = {Schatz, Thomas and Feldman, Naomi H. and Goldwater, Sharon and Cao, Xuan-Nga and Dupoux, Emmanuel},
	title = {Early phonetic learning without phonetic categories: Insights from large-scale simulations on realistic input},
	volume = {118},
	number = {7},
	year = {2021},
	abstract = {Infants become attuned to the sounds of their native language(s) before they even speak. Hypotheses about what is being learned by infants have traditionally driven researchers{\textquoteright} attempts to understand this surprising phenomenon. Here, we propose to start, instead, from hypotheses about how infants might learn. To implement this mechanism-driven approach, we introduce a quantitative modeling framework based on large-scale simulation of the learning process on realistic input. It allows learning mechanisms to be systematically linked to testable predictions regarding infants{\textquoteright} attunement to their native language(s). Through this framework, we obtain evidence for an account of infants{\textquoteright} attunement that challenges established theories about what infants are learning.Before they even speak, infants become attuned to the sounds of the language(s) they hear, processing native phonetic contrasts more easily than nonnative ones. For example, between 6 to 8 mo and 10 to 12 mo, infants learning American English get better at distinguishing English and [l], as in {\textquotedblleft}rock{\textquotedblright} vs. {\textquotedblleft}lock,{\textquotedblright} relative to infants learning Japanese. Influential accounts of this early phonetic learning phenomenon initially proposed that infants group sounds into native vowel- and consonant-like phonetic categories{\textemdash}like and [l] in English{\textemdash}through a statistical clustering mechanism dubbed {\textquotedblleft}distributional learning.{\textquotedblright} The feasibility of this mechanism for learning phonetic categories has been challenged, however. Here, we demonstrate that a distributional learning algorithm operating on naturalistic speech can predict early phonetic learning, as observed in Japanese and American English infants, suggesting that infants might learn through distributional learning after all. We further show, however, that, contrary to the original distributional learning proposal, our model learns units too brief and too fine-grained acoustically to correspond to phonetic categories. This challenges the influential idea that what infants learn are phonetic categories. More broadly, our work introduces a mechanism-driven approach to the study of early phonetic learning, together with a quantitative modeling framework that can handle realistic input. This allows accounts of early phonetic learning to be linked to concrete, systematic predictions regarding infants{\textquoteright} attunement.},
	link = {https://thomas.schatz.cogserver.net/pdf/schatz2021early.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}


@article{fourtassi2020growth,
  title={The growth of children's semantic and phonological networks: Insight from 10 languages},
  author={Fourtassi, Abdellah and Bian, Yuan and Frank, Michael C},
  journal={Cognitive Science},
  volume={44},
  number={7},
  pages={e12847},
  year={2020},
  publisher={Wiley Online Library},
  link ={https://psyarxiv.com/37npj},
  abstract ={Children tend to produce words earlier when they are connected to a variety of other words along the phonological and semantic dimensions. Though these semantic and phonological connectivity effects have been extensively documented, little is known about their underlying developmental mechanism. One possibility is that learning is driven by lexical network growth where highly connected words in the child's early lexicon enable learning of similar words. Another possibility is that learning is driven by highly connected words in the external learning environment, instead of highly connected words in the early internal lexicon. The present study tests both scenarios systematically in both the phonological and semantic domains across 10 languages. We show that phonological and semantic connectivity in the learning environment drives growth in both production- and comprehension-based vocabularies, even controlling for word frequency and length. This pattern of findings suggests a word learning process where children harness their statistical learning abilities to detect and learn highly connected words in the learning environment.},
  repo = {https://github.com/afourtassi/networks}
}

@article{francois2021Attenuated,
author = {François, Clément and Rodriguez-Fornells, Antoni and Teixidó, Maria and Agut, Thaïs and Bosch, Laura},
title = {Attenuated brain responses to speech sounds in moderate preterm infants at term age},
journal = {Developmental Science},
volume = {24},
number = {1},
pages = {e12990},
keywords = {EEG, MMN, preterms, speech processing, voice-onset time, vowel quality},
abstract = {Abstract Recent findings have revealed that very preterm neonates already show the typical brain responses to place of articulation changes in stop consonants, but data on their sensitivity to other types of phonetic changes remain scarce. Here, we examined the impact of 7–8 weeks of extra-uterine life on the automatic processing of syllables in 20 healthy moderate preterm infants (mean gestational age at birth 33 weeks) matched in maturational age with 20 full-term neonates, thus differing in their previous auditory experience. This design allows elucidating the contribution of extra-uterine auditory experience in the immature brain on the encoding of linguistically relevant speech features. Specifically, we collected brain responses to natural CV syllables differing in three dimensions using a multi-feature mismatch paradigm, with the syllable/ba/ as the standard and three deviants: a pitch change, a vowel change to/bo/ and a consonant voice-onset time (VOT) change to/pa/. No significant between-group differences were found for pitch and consonant VOT deviants. However, moderate preterm infants showed attenuated responses to vowel deviants compared to full terms. These results suggest that moderate preterm infants' limited experience with low-pass filtered speech prenatally can hinder vowel change detection and that exposure to natural speech after birth does not seem to contribute to improve this capacity. These data are in line with recent evidence suggesting a sequential development of a hierarchical functional architecture of speech processing that is highly sensitive to early auditory experience.},
year = {2021},
link = {https://pubmed.ncbi.nlm.nih.gov/32416634/}
}

@article{dautriche2021knowing,
  title={Knowing how you know: Toddlers reevaluate words learned from an unreliable speaker},
  author={Dautriche, Isabelle and Goupil, Louise and Smith, Kenny and Rabagliati, Hugh},
  journal={Open Mind},
  volume={5},
  pages={1--19},
  year={2021},
  link = {https://direct.mit.edu/opmi/article/doi/10.1162/opmi_a_00038/95934/Knowing-How-You-Know-Toddlers-Reevaluate-Words},
  repo = {https://osf.io/swdzc/},
  abstract = {There has been little investigation of the way source monitoring, the ability to track the source of one’s knowledge, may be involved in lexical acquisition. In two experiments, we tested whether toddlers (mean age 30 months) can monitor the source of their lexical knowledge and reevaluate their implicit belief about a word mapping when this source is proven to be unreliable. Experiment 1 replicated previous research (Koenig & Woodward, 2010): children displayed better performance in a word learning test when they learned words from a speaker who has previously revealed themself as reliable (correctly labeling familiar objects) as opposed to an unreliable labeler (incorrectly labeling familiar objects). Experiment 2 then provided the critical test for source monitoring: children first learned novel words from a speaker before watching that speaker labeling familiar objects correctly or incorrectly. Children who were exposed to the reliable speaker were significantly more likely to endorse the word mappings taught by the speaker than children who were exposed to a speaker who they later discovered was an unreliable labeler. Thus, young children can reevaluate recently learned word mappings upon discovering that the source of their knowledge is unreliable. This suggests that children can monitor the source of their knowledge in order to decide whether that knowledge is justified, even at an age where they are not credited with the ability to verbally report how they have come to know what they know.}
}

@article{fourtassi2021Continuous,
author = {Fourtassi, Abdellah and Regan, Sophie and Frank, Michael C.},
title = {Continuous developmental change explains discontinuities in word learning},
journal = {Developmental Science},
volume = {24},
number = {2},
abstract = {Cognitive development is often characterized in terms of discontinuities, but these discontinuities can sometimes be apparent rather than actual and can arise from continuous developmental change. To explore this idea, we use as a case study the finding by Stager and Werker (1997) that children's early ability to distinguish similar sounds does not automatically translate into word learning skills. Early explanations proposed that children may not be able to encode subtle phonetic contrasts when learning novel word meanings, thus suggesting a discontinuous/stage-like pattern of development. However, later work has revealed (e.g., through using more precise testing methods) that children do encode such contrasts, thus favoring a continuous pattern of development. Here, we propose a probabilistic model that represents word knowledge in a graded fashion and characterizes developmental change as improvement in the precision of this graded knowledge. Our model explained previous findings in the literature and provided a new prediction – the referents' visual similarity modulates word learning accuracy. The models' predictions were corroborated by human data collected from both preschool children and adults. The broader impact of this work is to show that computational models, such as ours, can help us explore the extent to which episodes of cognitive development that are typically thought of as discontinuities may emerge from simpler, continuous mechanisms.},
year = {2021},
repo = {https://github.com/afourtassi/kidswitch},
link = {https://psyarxiv.com/q98cp}
}

@inproceedings{mazzocconi2020laughter,
  title={Laughter growing up},
  author={Mazzocconi, Chiara and Ginzburg, Jonathan},
  booktitle={Proceedings of Laughter and Other Non-Verbal Vocalisations Workshop},
  year={2020},
  abstract= {We present a longitudinal corpus observation of laughter use in child-mother interaction from 12 to 36 months of age from a pragmatic perspective. The main aim of our work is to in- vestigate how laughter use in interaction may be informative about pragmatic development. We observe significant differences in child and mother use of laughter and changes over time as the child grows up, specifically in the fre- quency, in the pragmatic functions of laughter, and in the response to other’s laughter},
  link = {https://biecoll.ub.uni-bielefeld.de/index.php/lw2020/article/view/903/937}
  
}

@article{delecraz2020multimodal,
  title={Multimodal Machine Learning for Natural Language Processing: Disambiguating Prepositional Phrase Attachments with Images},
  author={Delecraz, Sebastien and Becerra-Bonache, Leonor and Favre, Benoit and Nasr, Alexis and Bechet, Frederic},
  journal={Neural Processing Letters},
  pages={1--27},
  year={2020},
  abstract = {Although documents are increasingly multimodal, their automatic processing is often monomodal. In particular, natural language processing tasks are typically performed based on the textual modality only. This work extends the syntactic parsing task to the image modality in addition to text. In particular, we address the prepositional phrase attachment problem, a hard and semantic problem for syntactic parsers. Given an image and a caption, the proposed approach resolves syntactic attachment of prepositions in the parse tree according to both visual and lexical features. Visual features are derived from the nature and position of detected objects in the image that are aligned to textual phrases in the caption. A reranker uses this information to reorder syntactic trees produced by a shift-reduce syntactic parser. Trained on the Flickr-PP corpus which contains multimodal gold-standard attachments, this approach yields improvements over a text-only syntactic parser, in particular for the subset of prepositions that encode location, leading to an increase of up to 17 points of attachment accuracy.},
  link= {https://link.springer.com/article/10.1007/s11063-020-10314-8}
}


@article{fourtassi2020how,
title = {How optimal is word recognition under multimodal uncertainty?},
journal = {Cognition},
volume = {199},
year = {2020},
author = {Abdellah Fourtassi and Michael C. Frank},
abstract = {Identifying a spoken word in a referential context requires both the ability to integrate multimodal input and the ability to reason under uncertainty. How do these tasks interact with one another? We study how adults identify novel words under joint uncertainty in the auditory and visual modalities, and we propose an ideal observer model of how cues in these modalities are combined optimally. Model predictions are tested in four experiments where recognition is made under various sources of uncertainty. We found that participants use both auditory and visual cues to recognize novel words. When the signal is not distorted with environmental noise, participants weight the auditory and visual cues optimally, that is, according to the relative reliability of each modality. In contrast, when one modality has noise added to it, human perceivers systematically prefer the unperturbed modality to a greater extent than the optimal model does. This work extends the literature on perceptual cue combination to the case of word recognition in a referential context. In addition, this context offers a link to the study of multimodal information in word meaning learning.},
repo = {https://github.com/afourtassi/WordRec},
link = {https://psyarxiv.com/qvr9j}
}



@inproceedings{Sitbon2020,
author = {Sitbon, Laurianne and Favre, Benoit and Brereton, Margot and Koplick, Stewart and Fell, Lauren},
title = {Engaging the Abilities of Participants with Intellectual Disabilityin IIR Research},
year = {2020},
publisher = {Association for Computing Machinery},
abstract = {Berget and MacFarlane pointed out the need for ethical methodologies
when involving participants with dyslexia. In this paper, we further propose that
a stance of ability based design and participatory design approaches can further involve,
engage and support people with intellectual disability in interactive information
retrieval (IIR) research. Through a case study with an accessible prototype designed
to access instructional videos, we demonstrate how an approach building on participant's
interests and providing them support as part of the study design leads to ecologically
valid observations. The accessible prototype makes use of images as prompts and query
support, and includes social aspects. Our observations confirm that users with intellectual
disability favour a visual approach to information access and interaction. The contributions
of this work are primarily 1) a 2 step approach with supported participatory design
approaches involving early prototypes 2) a case study of this approach to investigate
information access interfaces with people with intellectual disability and 3) a reflection
on the case study and applicability of the method in IIR evaluation.},
booktitle = {Proceedings of the 2020 Conference on Human Information Interaction and Retrieval},
pages = {103–112},
link = {https://dl.acm.org/doi/abs/10.1145/3343413.3377972}
}


